---
title: "The relative bias in alternative measures of BBS annual indices of abundance"
site: workflowr::wflow_site
output:
  workflowr::wflow_html:
    toc: false
editor_options:
  chunk_output_type: console
---

# Alternative Measures of Annual Indices

Bill Link's memo from October 15 outlines the differences in precision for two ways of estimating BBS annual indices. Here I'll use real BBS data to demonstrate the differences in accuracy of the two approaches, i.e., that using A1 results in a systematic over-estimation of the mean observed counts. And, demonstrate that the biased estimates of precision in the annual indices from using the A2 approach (defined below) do not translate into biased estimates of precision in the trends.  

## Estimating the annual indices using A1 or A2

A1 is the standard BBS approach, with n calculated following Sauer and Link 2011, as the expected count from a new observer-route combination. 

A2 is the approach I (Adam Smith) have been using lately, with n calculated as the mean of the expected counts from existing observer-route combinations. 

```{r echo = F, message = F, warning = F}
#species = "Chestnut-collared Longspur"
species = "Wood Thrush"

library(bbsBayes)
library(tidyr)
library(ggplot2)
library(ggforce)
library(dplyr)
library(ggrepel)
load(paste0("C:/Users/smithac/Documents/BBSIndices/data/",species," jags_models.RData"))


```

I've run the standard BBS slope model on `r paste(species)` and calculated the annual indices using either A1 or A2. In this model the variance of the observer-route effects is a fixed effect estimated as a single value across the full survey (i.e., there is no parameter that estimates a stratum-specific observer-route variance).


## Continental Annual Index plots for each approach
These plots of the annual indices show the estimated annual indices from each model along with the observed mean counts for each year. It is relatively easy to see that there's a difference in teh precision of the two estimates. But, importantly, there's also a difference in the overall magnitude of the estimates.
```{r cache=F, message = F, fig.height= 5, fig.width=7, echo = F,warning = F}
cont.1 = generate_cont_indices(mod,alternate_n = "n2")
cont.2 = generate_cont_indices(mod)
plot_cont_indices(cont.1,species = "A1",add_observed_means = T)
plot_cont_indices(cont.2,species = "A2",add_observed_means = T)


strat.1 = generate_strata_indices(mod,alternate_n = "n2")
strat.2 = generate_strata_indices(mod)

p1 = plot_strata_indices(strat.1,species = "A1",add_observed_means = T)
p2 = plot_strata_indices(strat.2,species = "A2",add_observed_means = T)



```



```{r echo = F}
extr.obs.means <- function(modl,modname = ""){
  
obs.mean = as.data.frame(modl$mean$obs)
obs.mean$strat = 1:nrow(obs.mean)
names(obs.mean) = c(paste0("obser",1:(ncol(obs.mean)-1)),"strat")
obsmean = gather(data = obs.mean,value = "observer_route_mean", key = "Observer",-strat,na.rm = T)
obsmean[,"model"] = modname
return(obsmean)
}

obs.1.mean = extr.obs.means(mod,modname = "A1")


obs.2.mean = extr.obs.means(mod,modname = "A2")

obs.mean = rbind(obs.1.mean,obs.2.mean)
obs.mean = merge(obs.mean,strat.1$area_weights,by.x = "strat", by.y = "num")




# h1 = ggplot(data = obs.mean,aes(y = observer_route_mean,x = model))+
#   geom_dotplot(binaxis = "y", stackdir = "center",aes(group = model))+
#   facet_wrap(facets = ~region)
# 
# 
# h1 = ggplot(data = obs.mean)+
#   geom_qq_line(aes(sample = observer_route_mean))+
#   geom_qq(aes(sample = observer_route_mean))+
#   facet_wrap(facets = ~region)

h1 = ggplot(data = obs.mean, aes(observer_route_mean, group = model, fill = model))+
  geom_freqpoly(bins = 10)+
  facet_wrap(facets = ~region)



```


## A2 overestimates precision
As Bill described in his note, the A2 approach does appear to overestimate the precision of the annual indices. For example, if we look at the coefficient of variation for the annual indices, the CV of A2 is always smaller than the CV of A1
```{r echo = F,fig.width=12}
obssdobs <- obs.mean %>% 
  group_by(region) %>% 
  summarise(sd = sd(observer_route_mean))

sdobs = mod$summary["sdobs",]
obssdobs$sddif = sdobs["mean"]-obssdobs$sd
names(obssdobs)[1] = "Region"

strat1 = strat.1$data_summary
strat2 = strat.2$data_summary
strat1$model = "A1"
strat2$model = "A2"

stratall = rbind(strat2,strat1)
stratall$LIndex = log(stratall$Index)
preddif <- stratall %>% 
  group_by(Region,Year) %>% 
  summarise(dif_index = diff(LIndex)) %>% 
  group_by(Region) %>% 
  summarise(mean_dif_log = mean(dif_index)) 


stratall$cv = ((stratall$Index_q_0.95-stratall$Index_q_0.025)/(2*1.96))/stratall$Index

cvs = stratall %>% 
  group_by(Region,model) %>% 
  summarise(mcv = mean(cv))


cvp = ggplot(data = cvs,aes(x = Region,y = mcv,group = model, colour = model))+
  geom_point()+
  theme(axis.text.x = element_text(angle = 90))+
  labs(x = "",
       y = "Coefficient of Variation of Indices (SE/mean)",title = "Coefficient of Variation (SE/mean) of the annual indices",
       subtitle = "A2 estimates have a shorter CV than A1 estimates")+
  scale_y_continuous(limits = c(0,NA))
  

print(cvp)


```


## But A1 overestimates abundance (magnitude)
The magnitude of the predicted indices is mportant so that:

* users of the annual indices understand the intuitive interpretation of their values. When users see annual indices that are far higher than they expect, the integrity of the survey suffers.
* the predictions accurately represent what they're intended to represent (i.e., either the expected value of a new observer-route combination or the mean expected value for a new count on one of the existing observer-route combinations)
* the relative value of the predictions among strata reflect the "true" relative abundance of the species among strata


### A1 overestimates the magnitude of the annual indices, and more so, for some strata
Although simplified, I've used the estimated posterior means as simple estimates of:

* the observer-route effects within each stratum (obs[strat,observer])
* the sd of the observer effects (sdobs)
* the predicted annual index (n[strat,year])

I've also calculated the observed mean count in a given stratum and year for comparison

If we compare the differences between the modeled annual mean counts (A1 and A2) and the observed mean counts, this should provide a measure of:

* the accuracy of our predictions, on average across years and strata (how similar are the expected counts and the observed mean counts)
* the differences between the A1 and A2 approachs in the relative contribution of each region to the regional trends

What we see is that both approaches tend to over-estimate the observed mean counts. However, the A2 approach, generates predicted values that are much more similar to the observed mean counts (i.e. the zero-line below). 

```{r echo=F}


####
stratall$Ldifobs <- stratall$LIndex-log(stratall$obs_mean) 
obsdif <- stratall %>% 
  filter(!is.na(Ldifobs) & is.finite(Ldifobs)) %>% 
  group_by(Region,model) %>% 
  summarise(dif_lindex_obs = mean(Ldifobs,na.rm = T), med_dif_lindex_obs = median(Ldifobs,na.rm = T))

compdif2 = left_join(obssdobs,obsdif,by = "Region")
difdif = compdif2 %>% 
  select(dif_lindex_obs,sddif,model,Region) %>% 
  spread(key = model,value = dif_lindex_obs)
```

```{r, fig.height= 5, fig.width=7,echo = F}
difp = ggplot(data = compdif2,aes(y = dif_lindex_obs,x = sddif,group = model,colour = model))+
  geom_abline(slope = 0,intercept = 0,colour = grey(0.8),size = 2)+
    geom_segment(data = difdif,aes(x = sddif,y = A1,xend = sddif,yend = A2),
               colour = grey(0.5),inherit.aes = F,size = 1,
               arrow = arrow(type = "closed",length = unit(0.02,"npc")))+
  geom_point(size = 2)+
  #geom_linerange(data = difdif,aes(x = sddif,ymax = A1,ymin = A2),inherit.aes = F)+
  labs(x = "sdobs - sd(obs[stratum,1:nobserver[stratum]])",
       y = "Difference between predicted and observed mean counts",
       title = "A2 predicted values are closer to observed means")
  #geom_label_repel(data = difdif,aes(x = sddif,y = A1,label = Region),size = 1,inherit.aes = F)+
  #scale_y_continuous(limits = c(-1,1))
print(difp)

```



### The differences between the two approaches are partly a function of the relationship between the overall observer-route variance and the stratum-level observer-route variance

The relationship between the overall observer-route variance (observer variance used in the 0.5*variance retransformation factor of approach A1), and the stratum-level variance of the observer-route effects (variance of the observer-route effects in a given stratum) partly explains why the magnitude of the two sets of estimates differ. The difference between the observed variance of observer-route effects in a given stratum (sd(obs[stratum,1:nobserver[stratum]])) and the overall sdobs provides a measure of how well the sdobs parameter represents the sd of the observer-route effects in a given stratum.

As you see below, this measure of the difference between the two estimates of observer-route variance is correlated with the difference between the mean predicted annual index from each model (average of the annual differences between model predictions).


```{r echo = F, fig.height= 5, fig.width=7}

compdif = left_join(obssdobs,preddif,by = "Region")

difp = ggplot(data = compdif,aes(y = mean_dif_log,x = sddif))+
  geom_hline(yintercept = 0,colour = grey(0.5))+
  geom_vline(xintercept = 0,colour = grey(0.5))+
  geom_point()+
  labs(x = "sdobs - sd(obs[stratum,1:nobserver[stratum]])",
       y = "Mean log-scale annual diff (mean(log(A1)-log(A2)))",
       title = "Magnitude difference of annual indices by observer-route variance",
       subtitle = "Little difference in strata where observer-route effects reflect the survey-wide pattern")
  #geom_label_repel(aes(label = Region))
print(difp)

```

This difference between the stratum-level observer variance and the overall observer variance is one of the reasons I suggested letting the observer variance vary among strata. Taking that approach has very similar effects on the index estimates as does using the A2 approach. I've more recently been using the A2 approach with an overall observer variance because it improves convergence for species and regions where the data are particularly sparse (i.e., avoids some situations where there is very little information available to estimate the variance of observer-route effects in a given stratum).

## Either way (A1 or A2), the stratum-level trends are the same, 
## However, the Continental trends are different!

Finally, we can look at the differences in the trends estimated by each approach, both at a stratum level and at the continental scale

```{r echo=F}
t.cont1 = generate_cont_trend(cont.1)
t.cont2 = generate_cont_trend(cont.2)
t.cont1$model = "A1"
t.cont2$model = "A2"
t.cont = rbind(t.cont1,t.cont2)
t.cont$CIWidth_Trend = t.cont$Trend_Q0.95-t.cont$Trend_Q0.025



t.strat1 = generate_strata_trends(strat.1)
t.strat2 = generate_strata_trends(strat.2)
t.strat1$model = "A1"
t.strat2$model = "A2"
t.strat = rbind(t.strat1,t.strat2)
t.strat$CIWidth_Trend = t.strat$Trend_Q0.95-t.strat$Trend_Q0.025

t.strat = rbind(t.cont,t.strat)
t.strat$Region = factor(t.strat$Region,levels = unique(t.strat$Region),ordered = T)
```
what we see is that the stratum level trends are effectively identical, both in their magnitude and in their uncertainty, but the continental estimates depend on the scaling (A1 vs A2). The continental trends vary because the relative magnitude of the annual indices in each stratum partly determine the stratum's contribution to the continental trend. If the annual indices are more severly overestimated in a stratum with a different trend value, then that increases the stratum's influence on the overall trend. For example, the continental trend from the A1 estimates is slightly less negative partly because of the much greater weight given to strata MT-11, CO-18, and ND-17 by the A1 calculation than is given by the A2 approach.

Given that the A2 approach:

* better represents the magnitude of the observed mean counts (and presumably the true relative abundance of birds among strata)
* is more independent of the relationship between sdobs and the sd(obs[stratum,1:nobservers]),

and, that the overestimate of precision in the indices from the A2 approach (which Bill L. demonstrated in his note from October 15) does not appear to translate into overestimates in the trend precision
It seems to me that the A2 approach is preferable
```{r echo = F,fig.width=12}

tp = ggplot(data = t.strat,aes(x = Region,y = Trend,group = model, colour = model))+
  geom_pointrange(aes(ymin = Trend_Q0.025,ymax = Trend_Q0.975),position = position_dodge(0.5))+
  theme(axis.text.x = element_text(angle = 90))+
  labs(x = "",title = "Continental and stratum-level trends using A1 and A2 calculations for annual indices",
       subtitle = "Continental trends vary by method but stratum-level trends are the same in magnitude and uncertainty")+
  scale_y_continuous(limits = c(-10,10))
  

print(tp)



```


Below are the annual index plots for each stratum and method.
Grey dots are the observed mean counts

```{r message = F,fig.height = 4, fig.width = 7, echo = F, warning = F}
for(i in 1:length(p1)){
  print(p1[[i]])
  print(p2[[i]])
  ### render(input = "C:/Users/smithac/Documents/BBSIndices/analysis/index.rmd",pdf_document())
}

```




